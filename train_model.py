"""
Script Principal de Entrenamiento - Stress Vision
Pipeline completo de entrenamiento del modelo de detecci√≥n de estr√©s

Flujo:
1. Cargar datos procesados
2. Construir modelo
3. Entrenar con callbacks
4. Evaluar en test set
5. Guardar modelo final
6. Convertir a TFLite (opcional)

Autor: Gloria S.A.
Fecha: 2024
"""

import os
import numpy as np
import json
from datetime import datetime

# Importar m√≥dulos del proyecto
from model_architecture import StressDetectionModel
from model_trainer import ModelTrainer
from convert_to_tflite import TFLiteConverter


def load_processed_data(data_dir='data/processed'):
    """
    Carga datos procesados desde archivos NPZ.
    
    Args:
        data_dir: Directorio con datos procesados
        
    Returns:
        train_data, val_data, test_data, metadata
    """
    print("\n" + "="*80)
    print("üì• CARGANDO DATOS PROCESADOS")
    print("="*80)
    print(f"   Directorio: {data_dir}\n")
    
    # Verificar que existen los archivos
    required_files = ['train_data.npz', 'val_data.npz', 'test_data.npz', 'metadata.json']
    for filename in required_files:
        filepath = os.path.join(data_dir, filename)
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Archivo requerido no encontrado: {filepath}")
    
    # Cargar datos
    train_data = np.load(os.path.join(data_dir, 'train_data.npz'))
    val_data = np.load(os.path.join(data_dir, 'val_data.npz'))
    test_data = np.load(os.path.join(data_dir, 'test_data.npz'))
    
    # Cargar metadata
    with open(os.path.join(data_dir, 'metadata.json'), 'r') as f:
        metadata = json.load(f)
    
    print(f"‚úÖ Datos cargados:")
    print(f"   ‚Ä¢ Train: {len(train_data['images'])} im√°genes")
    print(f"   ‚Ä¢ Validation: {len(val_data['images'])} im√°genes")
    print(f"   ‚Ä¢ Test: {len(test_data['images'])} im√°genes")
    print(f"   ‚Ä¢ Clases: {metadata['target_emotions']}")
    print("="*80)
    
    return (
        (train_data['images'], train_data['labels']),
        (val_data['images'], val_data['labels']),
        (test_data['images'], test_data['labels']),
        metadata
    )


def create_experiment_config(backbone, learning_rate, epochs, batch_size, 
                             use_augmentation, dropout_rate):
    """
    Crea configuraci√≥n del experimento.
    
    Returns:
        config: Dict con configuraci√≥n
    """
    config = {
        'experiment_name': datetime.now().strftime("%Y%m%d_%H%M%S"),
        'timestamp': datetime.now().isoformat(),
        'model': {
            'backbone': backbone,
            'dropout_rate': dropout_rate,
            'input_shape': [160, 160, 3],
            'num_classes': 5
        },
        'training': {
            'epochs': epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'use_augmentation': use_augmentation
        },
        'target_device': 'Raspberry Pi 5',
        'objective': 'Detecci√≥n de estr√©s laboral',
        'kpis': {
            'accuracy_target': 0.84,
            'latency_target_ms': 200
        }
    }
    
    return config


def save_experiment_results(config, history, test_results, output_dir):
    """
    Guarda resultados del experimento.
    
    Args:
        config: Configuraci√≥n del experimento
        history: Historial de entrenamiento
        test_results: Resultados en test set
        output_dir: Directorio de salida
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # Agregar resultados a config
    config['results'] = {
        'final_train_accuracy': float(history.history['accuracy'][-1]),
        'final_val_accuracy': float(history.history['val_accuracy'][-1]),
        'best_val_accuracy': float(max(history.history['val_accuracy'])),
        'final_train_loss': float(history.history['loss'][-1]),
        'final_val_loss': float(history.history['val_loss'][-1]),
        'epochs_trained': len(history.history['loss']),
        'test_metrics': test_results
    }
    
    # Guardar configuraci√≥n y resultados
    with open(os.path.join(output_dir, 'experiment_config.json'), 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"   ‚úì Configuraci√≥n guardada en: {output_dir}/experiment_config.json")
    
    # Guardar historial de entrenamiento
    history_dict = {key: [float(v) for v in values] 
                   for key, values in history.history.items()}
    
    with open(os.path.join(output_dir, 'training_history.json'), 'w') as f:
        json.dump(history_dict, f, indent=2)
    
    print(f"   ‚úì Historial guardado en: {output_dir}/training_history.json")


def main():
    """Funci√≥n principal de entrenamiento."""
    
    print("\n" + "="*100)
    print(" "*30 + "ü§ñ ENTRENAMIENTO DEL MODELO")
    print(" "*30 + "STRESS VISION - GLORIA S.A.")
    print("="*100)
    print("\nFase 4: Entrenamiento y Optimizaci√≥n del Modelo")
    print("Objetivo: Detectar estr√©s laboral con ‚â•84% accuracy y ‚â§200ms latencia")
    print("\n" + "="*100)
    
    # ========================================
    # 1. CARGAR DATOS
    # ========================================
    try:
        train_data, val_data, test_data, metadata = load_processed_data('data/processed')
        class_names = metadata['target_emotions']
        num_classes = len(class_names)
    except FileNotFoundError as e:
        print(f"\n‚ùå Error: {e}")
        print("\nüí° Primero debe preparar los datos:")
        print("   python data_preparation.py")
        return
    
    # ========================================
    # 2. CONFIGURAR ENTRENAMIENTO
    # ========================================
    print("\n" + "="*100)
    print("‚öôÔ∏è  CONFIGURACI√ìN DEL ENTRENAMIENTO")
    print("="*100)
    
    print("\nüìã Opciones de arquitectura:")
    print("1. MobileNetV3-Small (Recomendado)")
    print("   ‚Ä¢ Transfer learning de ImageNet")
    print("   ‚Ä¢ ~4-6 MB")
    print("   ‚Ä¢ Alta precisi√≥n")
    print("\n2. Custom Light")
    print("   ‚Ä¢ Arquitectura custom ultra-ligera")
    print("   ‚Ä¢ ~1-2 MB")
    print("   ‚Ä¢ M√°xima velocidad")
    
    backbone_opt = input("\nSeleccione arquitectura (1/2) [1]: ").strip()
    backbone = 'custom_light' if backbone_opt == '2' else 'mobilenetv3'
    
    # Hiperpar√°metros
    print("\nüìä Hiperpar√°metros:")
    
    epochs = input("√âpocas m√°ximas [50]: ").strip()
    epochs = int(epochs) if epochs else 50
    
    batch_size = input("Batch size [32]: ").strip()
    batch_size = int(batch_size) if batch_size else 32
    
    lr = input("Learning rate [0.001]: ").strip()
    learning_rate = float(lr) if lr else 0.001
    
    dropout = input("Dropout rate [0.3]: ").strip()
    dropout_rate = float(dropout) if dropout else 0.3
    
    aug = input("\n¬øUsar data augmentation en training? (s/n) [s]: ").strip().lower()
    use_augmentation = aug != 'n'
    
    # Crear configuraci√≥n
    config = create_experiment_config(
        backbone, learning_rate, epochs, batch_size, 
        use_augmentation, dropout_rate
    )
    
    experiment_name = config['experiment_name']
    
    print(f"\n‚úÖ Configuraci√≥n completa")
    print(f"   ‚Ä¢ Experimento: {experiment_name}")
    print(f"   ‚Ä¢ Backbone: {backbone}")
    print(f"   ‚Ä¢ √âpocas: {epochs}")
    print(f"   ‚Ä¢ Batch size: {batch_size}")
    print(f"   ‚Ä¢ Learning rate: {learning_rate}")
    print(f"   ‚Ä¢ Dropout: {dropout_rate}")
    print(f"   ‚Ä¢ Data augmentation: {use_augmentation}")
    
    # ========================================
    # 3. CONSTRUIR MODELO
    # ========================================
    print("\n" + "="*100)
    print("üèóÔ∏è  CONSTRUCCI√ìN DEL MODELO")
    print("="*100)
    
    model_builder = StressDetectionModel(
        num_classes=num_classes,
        input_shape=(160, 160, 3)
    )
    
    model = model_builder.build_model(
        backbone=backbone,
        dropout_rate=dropout_rate
    )
    
    model = model_builder.compile_model(
        model,
        learning_rate=learning_rate
    )
    
    # ========================================
    # 4. ENTRENAR MODELO
    # ========================================
    print("\n" + "="*100)
    print("üöÄ ENTRENAMIENTO")
    print("="*100)
    
    trainer = ModelTrainer(
        model=model,
        train_data=train_data,
        val_data=val_data,
        class_names=class_names
    )
    
    history = trainer.train(
        epochs=epochs,
        batch_size=batch_size,
        experiment_name=experiment_name,
        use_data_augmentation=use_augmentation
    )
    
    # ========================================
    # 5. EVALUAR EN TEST SET
    # ========================================
    print("\n" + "="*100)
    print("üìä EVALUACI√ìN FINAL")
    print("="*100)
    
    test_results = trainer.evaluate(test_data, plot_results=True)
    
    # Verificar KPIs
    print("\n" + "="*100)
    print("üéØ VERIFICACI√ìN DE KPIs")
    print("="*100)
    
    test_accuracy = test_results['accuracy']
    target_accuracy = 0.84
    
    print(f"\nüìà Accuracy:")
    print(f"   ‚Ä¢ Test accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print(f"   ‚Ä¢ Target: {target_accuracy:.4f} ({target_accuracy*100:.2f}%)")
    
    if test_accuracy >= target_accuracy:
        print(f"   ‚úÖ CUMPLE KPI de accuracy")
    else:
        diff = (target_accuracy - test_accuracy) * 100
        print(f"   ‚ö†Ô∏è  Falta {diff:.2f}% para cumplir KPI")
        print(f"   üí° Sugerencias:")
        print(f"      ‚Ä¢ Aumentar dataset (data augmentation)")
        print(f"      ‚Ä¢ Ajustar learning rate")
        print(f"      ‚Ä¢ Probar MobileNetV3 si us√≥ Custom Light")
        print(f"      ‚Ä¢ Aumentar epochs")
    
    # ========================================
    # 6. GUARDAR MODELO Y RESULTADOS
    # ========================================
    print("\n" + "="*100)
    print("üíæ GUARDANDO RESULTADOS")
    print("="*100)
    
    output_dir = f"models/experiments/{experiment_name}"
    os.makedirs(output_dir, exist_ok=True)
    
    # Guardar modelo final
    final_model_path = f"{output_dir}/final_model.keras"
    model.save(final_model_path)
    print(f"   ‚úì Modelo guardado: {final_model_path}")
    
    # Guardar configuraci√≥n del modelo
    model_builder.save_model_config(model, f"{output_dir}/model_config.json")
    
    # Guardar resultados del experimento
    save_experiment_results(config, history, test_results, output_dir)
    
    # Graficar historial
    plot_path = f"{output_dir}/training_history.png"
    trainer.plot_training_history(save_path=plot_path)
    
    # ========================================
    # 7. CONVERSI√ìN A TFLITE (OPCIONAL)
    # ========================================
    print("\n" + "="*100)
    convert_opt = input("\n¬øConvertir a TensorFlow Lite ahora? (s/n) [s]: ").strip().lower()
    
    if convert_opt != 'n':
        print("\nüîÑ CONVERSI√ìN A TENSORFLOW LITE")
        print("="*100)
        
        converter = TFLiteConverter(final_model_path)
        
        tflite_dir = f"{output_dir}/tflite"
        os.makedirs(tflite_dir, exist_ok=True)
        
        # Convertir a INT8 (recomendado para Raspberry Pi)
        print("\nConvirtiendo a INT8 quantized...")
        tflite_path = converter.convert_int8(
            output_path=f"{tflite_dir}/model_int8.tflite"
        )
        
        if tflite_path:
            # Benchmark
            print("\n‚ö° Ejecutando benchmark...")
            latency_stats = converter.benchmark_latency(tflite_path, num_runs=100)
            
            # Guardar stats
            with open(f"{tflite_dir}/latency_stats.json", 'w') as f:
                json.dump(latency_stats, f, indent=2)
            
            print(f"\n‚úÖ Modelo TFLite guardado en: {tflite_dir}/")
    
    # ========================================
    # 8. RESUMEN FINAL
    # ========================================
    print("\n" + "="*100)
    print("‚úÖ ENTRENAMIENTO COMPLETADO")
    print("="*100)
    
    print(f"\nüìä Resumen del Experimento:")
    print(f"   ‚Ä¢ Experimento ID: {experiment_name}")
    print(f"   ‚Ä¢ Modelo: {backbone}")
    print(f"   ‚Ä¢ √âpocas entrenadas: {len(history.history['loss'])}")
    print(f"   ‚Ä¢ Mejor val accuracy: {max(history.history['val_accuracy']):.4f}")
    print(f"   ‚Ä¢ Test accuracy: {test_accuracy:.4f}")
    print(f"   ‚Ä¢ Test loss: {test_results['loss']:.4f}")
    
    if 'precision' in test_results:
        print(f"   ‚Ä¢ Precision: {test_results['precision']:.4f}")
        print(f"   ‚Ä¢ Recall: {test_results['recall']:.4f}")
    
    print(f"\nüìÅ Archivos guardados en: {output_dir}/")
    print(f"   ‚Ä¢ final_model.keras")
    print(f"   ‚Ä¢ model_config.json")
    print(f"   ‚Ä¢ experiment_config.json")
    print(f"   ‚Ä¢ training_history.json")
    print(f"   ‚Ä¢ training_history.png")
    if convert_opt != 'n':
        print(f"   ‚Ä¢ tflite/model_int8.tflite")
        print(f"   ‚Ä¢ tflite/latency_stats.json")
    
    print(f"\nüí° Pr√≥ximos pasos:")
    print(f"   1. Revisar m√©tricas en TensorBoard:")
    print(f"      tensorboard --logdir logs/{experiment_name}")
    print(f"   2. Evaluar modelo: python evaluate_model.py")
    print(f"   3. Desplegar en Raspberry Pi")
    
    print("\n" + "="*100 + "\n")


if __name__ == "__main__":
    main()


