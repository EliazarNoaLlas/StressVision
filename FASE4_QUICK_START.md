# âš¡ Quick Start - Fase 4: Entrenamiento del Modelo

## ğŸš€ Inicio RÃ¡pido (5 Pasos)

### Paso 1: Descargar FER-2013 (5 min)

```bash
# Instalar Kaggle CLI
pip install kaggle

# Configurar credenciales de Kaggle
# 1. Ir a kaggle.com â†’ Account â†’ Create New API Token
# 2. Copiar kaggle.json a ~/.kaggle/

# Descargar dataset
kaggle datasets download -d msambare/fer2013
unzip fer2013.zip -d data/fer2013/
```

---

### Paso 2: Preparar Datos (10-15 min)

```bash
python data_preparation.py
```

**Responder:**
- Â¿Usar FER-2013? â†’ `s`
- Path a fer2013.csv â†’ `Enter` (usa default)
- Â¿Usar dataset custom? â†’ `n` (por ahora)
- Â¿Aplicar data augmentation? â†’ `s`
- NÃºmero objetivo por clase â†’ `5000`
- Directorio de salida â†’ `Enter`

**Output:** `data/processed/` con train, val, test data

---

### Paso 3: Entrenar Modelo (2-4 horas)

```bash
python train_model.py
```

**ConfiguraciÃ³n recomendada para empezar:**
- Arquitectura â†’ `1` (MobileNetV3)
- Ã‰pocas â†’ `50`
- Batch size â†’ `32`
- Learning rate â†’ `0.001`
- Dropout â†’ `0.3`
- Data augmentation â†’ `s`
- Â¿Convertir a TFLite? â†’ `s`

**Monitorear en tiempo real:**
```bash
# En otra terminal
tensorboard --logdir logs/
# Abrir http://localhost:6006
```

---

### Paso 4: Evaluar Resultados (2 min)

```bash
python evaluate_model.py
```

- Seleccionar experimento (el mÃ¡s reciente)
- Revisar mÃ©tricas y confusion matrix

**Verificar:**
- âœ… Test accuracy â‰¥ 84%
- âœ… Latencia â‰¤ 200ms (si convirtiÃ³ a TFLite)

---

### Paso 5: Desplegar en Raspberry Pi

```bash
# 1. Copiar modelo a Raspberry Pi
scp models/experiments/[EXPERIMENT]/tflite/model_int8.tflite pi@raspberry:~/

# 2. En Raspberry Pi, probar latencia
python3 benchmark_tflite.py model_int8.tflite
```

---

## ğŸ“Š Resultados Esperados

### Con MobileNetV3-Small + FER-2013:

| MÃ©trica | Esperado | MÃ­nimo |
|---------|----------|--------|
| Test Accuracy | 85-90% | 84% |
| Precision | 83-88% | 80% |
| Recall | 83-88% | 80% |
| Modelo (.keras) | 5-7 MB | - |
| TFLite (INT8) | 1.5-2.5 MB | <10 MB |
| Latencia (RPi 5) | 150-200ms | â‰¤200ms |

---

## ğŸ”§ Si algo sale mal...

### Accuracy < 84%

```bash
# OpciÃ³n 1: MÃ¡s datos
python data_preparation.py
# Aumentar target_per_class a 8000-10000

# OpciÃ³n 2: MÃ¡s epochs
python train_model.py
# Aumentar epochs a 100

# OpciÃ³n 3: Fine-tuning mÃ¡s agresivo
# Editar model_architecture.py lÃ­nea 113
for layer in base_model.layers[:-50]:  # Entrenar mÃ¡s capas
```

### Latencia > 200ms

```bash
# OpciÃ³n 1: Usar Custom Light
python train_model.py
# Seleccionar arquitectura 2

# OpciÃ³n 2: Reducir input size
# Editar train_model.py lÃ­nea 205
input_shape=(120, 120, 3)  # Menos que 160x160

# OpciÃ³n 3: Coral USB TPU
# Comprar: ~$60
# Latencia esperada: 10-20ms
```

### Out of Memory

```bash
# Reducir batch size
python train_model.py
# batch_size = 16  # O incluso 8
```

---

## ğŸ’¡ Tips Pro

### 1. Usar GPU para entrenar mÃ¡s rÃ¡pido

```bash
# Verificar GPU disponible
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Si tienes GPU CUDA, el training serÃ¡ 5-10x mÃ¡s rÃ¡pido
# 2-4 horas â†’ 15-30 minutos
```

### 2. Guardar mÃºltiples experimentos

```python
# Los experimentos se guardan automÃ¡ticamente con timestamp
# Puedes entrenar mÃºltiples configuraciones y comparar:

# Experimento 1: MobileNetV3 + 50 epochs
python train_model.py

# Experimento 2: Custom Light + 100 epochs  
python train_model.py

# Comparar:
python evaluate_model.py
```

### 3. Transfer learning incremental

```python
# 1. Entrenar solo el head (primero)
for layer in base_model.layers:
    layer.trainable = False

# 2. Fine-tune capas superiores (despuÃ©s)
for layer in base_model.layers[-30:]:
    layer.trainable = True
```

---

## ğŸ“ Estructura Final

DespuÃ©s de completar todo:

```
StressVision/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fer2013/
â”‚   â”‚   â””â”€â”€ fer2013.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train_data.npz
â”‚       â”œâ”€â”€ val_data.npz
â”‚       â”œâ”€â”€ test_data.npz
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ experiments/
â”‚       â””â”€â”€ YYYYMMDD_HHMMSS/
â”‚           â”œâ”€â”€ final_model.keras
â”‚           â”œâ”€â”€ experiment_config.json
â”‚           â”œâ”€â”€ training_history.png
â”‚           â””â”€â”€ tflite/
â”‚               â”œâ”€â”€ model_int8.tflite
â”‚               â””â”€â”€ latency_stats.json
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ YYYYMMDD_HHMMSS/
â”‚       â””â”€â”€ (TensorBoard logs)
â”‚
â”œâ”€â”€ data_preparation.py
â”œâ”€â”€ model_architecture.py
â”œâ”€â”€ model_trainer.py
â”œâ”€â”€ convert_to_tflite.py
â”œâ”€â”€ train_model.py
â””â”€â”€ evaluate_model.py
```

---

## â±ï¸ Timeline Estimado

| Actividad | Tiempo |
|-----------|--------|
| Descargar FER-2013 | 5 min |
| Preparar datos | 10-15 min |
| Entrenar modelo | 2-4 horas |
| Evaluar | 2 min |
| Convertir TFLite | 5-10 min |
| **TOTAL** | **~3-5 horas** |

*Con GPU: ~1-2 horas total*

---

## ğŸ¯ PrÃ³ximos Pasos

DespuÃ©s de completar Fase 4:

1. âœ… **Fase 5: IntegraciÃ³n en Sistema de Monitoreo**
   - Integrar modelo TFLite en `main.py`
   - Reconocimiento en tiempo real
   - Asociar detecciones con empleados

2. âœ… **Fase 6: Dashboard Avanzado**
   - Visualizar estrÃ©s por empleado
   - Reportes automÃ¡ticos
   - Alertas personalizadas

3. âœ… **Fase 7: Despliegue en Raspberry Pi**
   - Configurar Raspberry Pi 5
   - Instalar dependencias
   - Pruebas en producciÃ³n

---

**Â¡Listo para entrenar tu modelo de detecciÃ³n de estrÃ©s! ğŸš€**

Gloria S.A. - Stress Vision


