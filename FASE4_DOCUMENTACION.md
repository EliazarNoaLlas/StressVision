# ğŸ¤– Fase 4: Entrenamiento y OptimizaciÃ³n del Modelo

## ğŸ“Š Resumen Ejecutivo

Esta fase implementa el entrenamiento completo del modelo de detecciÃ³n de estrÃ©s, desde la preparaciÃ³n de datos hasta la optimizaciÃ³n para Raspberry Pi 5.

---

## ğŸ¯ Objetivos de la Fase

### KPIs Objetivo:
- âœ… **Accuracy â‰¥ 84%** en test set
- âœ… **Latencia â‰¤ 200ms** por frame en Raspberry Pi 5
- âœ… **TamaÃ±o del modelo â‰¤ 10 MB** (TFLite quantized)
- âœ… **5 clases de emociÃ³n**: neutral, stress, sad, happy, fatigue

---

## ğŸ“ Archivos Creados

### MÃ³dulos Python (5 archivos)

| Archivo | LÃ­neas | DescripciÃ³n |
|---------|--------|-------------|
| `data_preparation.py` | 500+ | Carga y procesamiento de datasets |
| `model_architecture.py` | 400+ | Arquitecturas MobileNetV3 y Custom Light |
| `model_trainer.py` | 450+ | Sistema de entrenamiento con callbacks |
| `convert_to_tflite.py` | 400+ | ConversiÃ³n y quantization a TFLite |
| `train_model.py` | 350+ | Script principal de entrenamiento |
| `evaluate_model.py` | 250+ | EvaluaciÃ³n y anÃ¡lisis de resultados |

**Total: ~2,350 lÃ­neas de cÃ³digo**

---

## ğŸ”„ Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARACIÃ“N DE DATOS (data_preparation.py)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Cargar FER-2013 (28,709 imÃ¡genes)                          â”‚
â”‚ â€¢ Cargar dataset custom de Gloria                            â”‚
â”‚ â€¢ Mapeo de emociones â†’ [neutral, stress, sad, happy, fatigue]â”‚
â”‚ â€¢ Data augmentation para balanceo                            â”‚
â”‚ â€¢ DivisiÃ³n: 70% train / 15% val / 15% test                   â”‚
â”‚ â€¢ Guardar en NPZ: data/processed/                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONSTRUCCIÃ“N DEL MODELO (model_architecture.py)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ OpciÃ³n A: MobileNetV3-Small                                  â”‚
â”‚   â€¢ Transfer learning de ImageNet                            â”‚
â”‚   â€¢ Fine-tuning de Ãºltimas 30 capas                          â”‚
â”‚   â€¢ Custom head: Dense(256) â†’ Dense(128) â†’ Softmax(5)        â”‚
â”‚   â€¢ ~4-6 MB                                                   â”‚
â”‚                                                               â”‚
â”‚ OpciÃ³n B: Custom Light                                       â”‚
â”‚   â€¢ Arquitectura custom con Separable Convolutions           â”‚
â”‚   â€¢ Optimizado para CPU                                      â”‚
â”‚   â€¢ ~1-2 MB                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENTRENAMIENTO (model_trainer.py + train_model.py)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Optimizer: Adam (lr=0.001)                                 â”‚
â”‚ â€¢ Loss: Categorical Crossentropy                             â”‚
â”‚ â€¢ Callbacks:                                                  â”‚
â”‚   - EarlyStopping (patience=10)                              â”‚
â”‚   - ModelCheckpoint (guardar mejor modelo)                   â”‚
â”‚   - ReduceLROnPlateau (factor=0.5)                           â”‚
â”‚   - TensorBoard logging                                      â”‚
â”‚   - CSV logger                                                â”‚
â”‚ â€¢ Data augmentation en training (opcional)                   â”‚
â”‚ â€¢ MÃ©tricas: accuracy, precision, recall, AUC                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EVALUACIÃ“N (evaluate_model.py)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ MÃ©tricas globales en test set                              â”‚
â”‚ â€¢ Classification report por clase                            â”‚
â”‚ â€¢ Matriz de confusiÃ³n                                        â”‚
â”‚ â€¢ AnÃ¡lisis de errores mÃ¡s comunes                            â”‚
â”‚ â€¢ Visualizaciones: confusion matrix, historial training      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. OPTIMIZACIÃ“N PARA RASPBERRY PI (convert_to_tflite.py)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ConversiÃ³n a TensorFlow Lite                               â”‚
â”‚ â€¢ Quantization INT8 (reducciÃ³n 4x de tamaÃ±o)                 â”‚
â”‚ â€¢ Benchmark de latencia (100 runs)                           â”‚
â”‚ â€¢ VerificaciÃ³n de KPI â‰¤ 200ms                                â”‚
â”‚ â€¢ Output: model_int8.tflite (~1-3 MB)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ GuÃ­a de Uso

### Paso 1: Preparar Datos

```bash
python data_preparation.py
```

**Requisitos previos:**
- Descargar FER-2013 de [Kaggle](https://www.kaggle.com/datasets/msambare/fer2013)
- (Opcional) Preparar dataset custom en `data/custom_dataset/`

**Estructura esperada:**
```
data/
â”œâ”€â”€ fer2013/
â”‚   â””â”€â”€ fer2013.csv
â””â”€â”€ custom_dataset/
    â”œâ”€â”€ neutral/
    â”œâ”€â”€ stress/
    â”œâ”€â”€ sad/
    â”œâ”€â”€ happy/
    â””â”€â”€ fatigue/
```

**Output:**
```
data/processed/
â”œâ”€â”€ train_data.npz
â”œâ”€â”€ val_data.npz
â”œâ”€â”€ test_data.npz
â””â”€â”€ metadata.json
```

---

### Paso 2: Entrenar Modelo

```bash
python train_model.py
```

**ParÃ¡metros configurables:**
- Arquitectura: MobileNetV3 o Custom Light
- Ã‰pocas mÃ¡ximas: 50 (default)
- Batch size: 32 (default)
- Learning rate: 0.001 (default)
- Dropout rate: 0.3 (default)
- Data augmentation: SÃ­ (default)

**Durante el entrenamiento:**
- Se guardan checkpoints cada Ã©poca
- EarlyStopping detiene si no mejora en 10 Ã©pocas
- TensorBoard registra todas las mÃ©tricas
- CSV log guarda historial

**Output:**
```
models/experiments/YYYYMMDD_HHMMSS/
â”œâ”€â”€ final_model.keras
â”œâ”€â”€ model_config.json
â”œâ”€â”€ experiment_config.json
â”œâ”€â”€ training_history.json
â”œâ”€â”€ training_history.png
â””â”€â”€ checkpoints/
    â””â”€â”€ best_model.keras
```

---

### Paso 3: Evaluar Modelo

```bash
python evaluate_model.py
```

Selecciona el experimento a evaluar.

**Output:**
- MÃ©tricas globales
- Classification report
- Matriz de confusiÃ³n (PNG)
- AnÃ¡lisis de errores
- JSON con resultados

---

### Paso 4: Convertir a TFLite

OpciÃ³n A: Durante training (automÃ¡tico si acepta)

OpciÃ³n B: Manual
```bash
python convert_to_tflite.py
```

**Tipos de conversiÃ³n disponibles:**
1. Float32: Sin optimizaciÃ³n (mÃ¡xima precisiÃ³n)
2. Float16: ~50% reducciÃ³n
3. INT8 Quantized: ~75% reducciÃ³n (RECOMENDADO)

**Benchmark de latencia:**
- 100 ejecuciones
- Calcula: mean, std, p50, p95, p99, FPS
- Verifica KPI â‰¤ 200ms

---

## ğŸ“Š Datasets Soportados

### 1. FER-2013 (Principal)

- **Origen:** Kaggle
- **ImÃ¡genes:** 28,709
- **ResoluciÃ³n:** 48x48 pixels (grayscale)
- **Clases originales:** 7 (angry, disgust, fear, happy, sad, surprise, neutral)
- **Mapeo a nuestras clases:**
  - angry, fear, disgust â†’ **stress**
  - sad â†’ **sad**
  - neutral, surprise â†’ **neutral**
  - happy â†’ **happy**

**Descarga:**
```bash
# Instalar Kaggle CLI
pip install kaggle

# Descargar FER-2013
kaggle datasets download -d msambare/fer2013
unzip fer2013.zip -d data/fer2013/
```

### 2. Dataset Custom de Gloria

Estructura:
```
data/custom_dataset/
â”œâ”€â”€ neutral/
â”œâ”€â”€ stress/
â”œâ”€â”€ sad/
â”œâ”€â”€ happy/
â””â”€â”€ fatigue/
```

**CÃ³mo crear:**
1. Capturar fotos de empleados en diferentes estados
2. Organizar en carpetas por emociÃ³n
3. Formato: JPG, PNG (160x160 recomendado)
4. MÃ­nimo: 100 imÃ¡genes por clase

---

## ğŸ—ï¸ Arquitecturas del Modelo

### OpciÃ³n 1: MobileNetV3-Small (Recomendado)

**Ventajas:**
- Pre-entrenado en ImageNet (transfer learning)
- Alta precisiÃ³n (esperada: 85-90%)
- Optimizado para mÃ³viles/edge devices
- Squeeze-and-Excitation para mejor feature extraction

**Desventajas:**
- ~4-6 MB (mÃ¡s pesado que Custom Light)
- Latencia ligeramente mayor

**Arquitectura:**
```python
Input (160x160x3)
  â†“
Preprocessing (normalizaciÃ³n [-1, 1])
  â†“
MobileNetV3Small backbone (ImageNet)
  â†“ (fine-tuning Ãºltimas 30 capas)
GlobalAveragePooling2D
  â†“
Dropout(0.3)
  â†“
Dense(256, relu) + L2(0.001) + BatchNorm
  â†“
Dropout(0.2)
  â†“
Dense(128, relu) + L2(0.001) + BatchNorm
  â†“
Dense(5, softmax)
```

### OpciÃ³n 2: Custom Light

**Ventajas:**
- Ultra-ligero (~1-2 MB)
- Latencia mÃ­nima
- Optimizado especÃ­ficamente para CPU Raspberry Pi

**Desventajas:**
- PrecisiÃ³n ligeramente menor (esperada: 80-85%)
- Sin transfer learning

**Arquitectura:**
```python
Input (160x160x3)
  â†“
Rescaling (1/255)
  â†“
Conv2D(32, 3x3, stride=2) + BN + ReLU + MaxPool
  â†“
SeparableConv2D(64, 3x3) + BN + ReLU + MaxPool
  â†“
SeparableConv2D(128, 3x3) + BN + ReLU + MaxPool
  â†“
SeparableConv2D(256, 3x3) + BN + ReLU
  â†“
GlobalAveragePooling2D
  â†“
Dropout(0.3)
  â†“
Dense(128, relu)
  â†“
Dense(5, softmax)
```

---

## âš™ï¸ HiperparÃ¡metros Recomendados

### Training

| ParÃ¡metro | Valor Default | Rango Recomendado |
|-----------|---------------|-------------------|
| Ã‰pocas | 50 | 30-100 |
| Batch Size | 32 | 16-64 |
| Learning Rate | 0.001 | 0.0001-0.01 |
| Dropout | 0.3 | 0.2-0.5 |
| L2 Regularization | 0.001 | 0.0001-0.01 |
| Optimizer | Adam | Adam, SGD+momentum |

### Data Augmentation

| TÃ©cnica | Valor |
|---------|-------|
| Rotation | Â±10-15Â° |
| Width/Height Shift | Â±10% |
| Horizontal Flip | SÃ­ |
| Brightness | [0.9, 1.1] |
| Zoom | Â±5% |

---

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

### MÃ©tricas Globales

- **Accuracy**: % de predicciones correctas
- **Precision**: TP / (TP + FP)
- **Recall**: TP / (TP + FN)
- **F1-Score**: Media armÃ³nica de precision y recall
- **AUC**: Ãrea bajo curva ROC

### Por Clase

Classification Report muestra precision, recall, f1-score para cada emociÃ³n:
- neutral
- stress
- sad
- happy
- fatigue

### Matriz de ConfusiÃ³n

Visualiza confusiones entre clases:
- Diagonal: Predicciones correctas
- Off-diagonal: Errores

---

## ğŸ”§ Troubleshooting

### Problema 1: Accuracy muy baja (<70%)

**Causas posibles:**
- Dataset desbalanceado
- Modelo muy simple
- HiperparÃ¡metros inadecuados
- Overfitting/Underfitting

**Soluciones:**
```bash
# 1. Aplicar data augmentation mÃ¡s agresivo
use_augmentation = True
target_per_class = 5000  # en data_preparation.py

# 2. Usar MobileNetV3 en lugar de Custom Light
backbone = 'mobilenetv3'

# 3. Ajustar learning rate
learning_rate = 0.0001  # MÃ¡s bajo

# 4. Aumentar epochs
epochs = 100
```

### Problema 2: Overfitting (val_loss >> train_loss)

**Soluciones:**
```python
# 1. Aumentar dropout
dropout_rate = 0.5

# 2. Aumentar data augmentation
# 3. Aplicar L2 regularization mÃ¡s fuerte
# 4. Early stopping mÃ¡s agresivo
patience = 5
```

### Problema 3: Latencia > 200ms

**Soluciones:**
```bash
# 1. Usar Custom Light en lugar de MobileNetV3
backbone = 'custom_light'

# 2. Reducir input size
input_shape = (120, 120, 3)  # En lugar de 160x160

# 3. Usar INT8 quantization
python convert_to_tflite.py  # OpciÃ³n 3

# 4. Considerar Coral USB TPU (~$60)
# Latencia: ~10-20ms
```

### Problema 4: Modelo muy grande

**Soluciones:**
```bash
# 1. ConversiÃ³n a TFLite INT8
# Original: 10-20 MB â†’ Quantized: 2-5 MB

# 2. Usar Custom Light
backbone = 'custom_light'  # ~1-2 MB

# 3. Reducir nÃºmero de filtros
# Modificar arquitectura en model_architecture.py
```

---

## ğŸ¯ Casos de Uso

### Caso 1: MÃ¡xima PrecisiÃ³n (InvestigaciÃ³n)

```python
backbone = 'mobilenetv3'
epochs = 100
batch_size = 16
learning_rate = 0.0001
dropout_rate = 0.3
use_augmentation = True
target_per_class = 10000  # Dataset muy grande
```

### Caso 2: Balance PrecisiÃ³n-Velocidad (ProducciÃ³n)

```python
backbone = 'mobilenetv3'
epochs = 50
batch_size = 32
learning_rate = 0.001
dropout_rate = 0.3
use_augmentation = True
# + ConversiÃ³n INT8
```

### Caso 3: MÃ¡xima Velocidad (Tiempo Real)

```python
backbone = 'custom_light'
input_shape = (120, 120, 3)
epochs = 50
batch_size = 64
learning_rate = 0.001
dropout_rate = 0.2
# + ConversiÃ³n INT8
```

---

## ğŸ“Š Resultados Esperados

### MobileNetV3-Small

| MÃ©trica | Esperado |
|---------|----------|
| Test Accuracy | 85-90% |
| Precision (avg) | 83-88% |
| Recall (avg) | 83-88% |
| TamaÃ±o (Keras) | ~5-7 MB |
| TamaÃ±o (TFLite INT8) | ~1.5-2.5 MB |
| Latencia (Raspberry Pi 5) | 150-200ms |

### Custom Light

| MÃ©trica | Esperado |
|---------|----------|
| Test Accuracy | 80-85% |
| Precision (avg) | 78-83% |
| Recall (avg) | 78-83% |
| TamaÃ±o (Keras) | ~2-3 MB |
| TamaÃ±o (TFLite INT8) | ~0.7-1.0 MB |
| Latencia (Raspberry Pi 5) | 80-120ms |

---

## ğŸ’¡ Mejores PrÃ¡cticas

### 1. PreparaciÃ³n de Datos

âœ… **DO:**
- Balancear clases con augmentation
- Usar validation set separado
- Normalizar inputs ([-1, 1] o [0, 1])
- Mezclar (shuffle) datasets combinados

âŒ **DON'T:**
- Usar datos de test para entrenamiento
- Ignorar desbalance de clases
- Olvidar normalizar

### 2. Entrenamiento

âœ… **DO:**
- Usar EarlyStopping para evitar overfitting
- Guardar checkpoints frecuentemente
- Monitorear val_loss y val_accuracy
- Usar TensorBoard para visualizar mÃ©tricas

âŒ **DON'T:**
- Entrenar sin validation set
- Ignorar overfitting (val_loss aumenta)
- Usar learning rate muy alto
- Olvidar data augmentation

### 3. EvaluaciÃ³n

âœ… **DO:**
- Evaluar en test set nunca visto
- Analizar confusion matrix
- Revisar errores mÃ¡s comunes
- Calcular mÃ©tricas por clase

âŒ **DON'T:**
- Evaluar solo accuracy global
- Ignorar clases desbalanceadas
- Olvidar analizar errores

### 4. OptimizaciÃ³n

âœ… **DO:**
- Usar INT8 quantization para producciÃ³n
- Hacer benchmark de latencia
- Verificar precisiÃ³n post-quantization
- Considerar Coral TPU si latencia crÃ­tica

âŒ **DON'T:**
- Desplegar modelo sin optimizar
- Ignorar latencia en dispositivo real
- Sacrificar mucha precisiÃ³n por velocidad

---

## ğŸ“š Referencias

### Papers

1. **MobileNetV3**: "Searching for MobileNetV3" (Howard et al., 2019)
2. **FER-2013**: "Challenges in Representation Learning" (Goodfellow et al., 2013)
3. **Transfer Learning**: "A Survey on Transfer Learning" (Pan & Yang, 2010)
4. **Quantization**: "Quantization and Training of Neural Networks" (Jacob et al., 2018)

### Datasets

- FER-2013: https://www.kaggle.com/datasets/msambare/fer2013
- AffectNet: http://mohammadmahoor.com/affectnet/
- RAF-DB: http://www.whdeng.cn/raf/model1.html

### Tools

- TensorFlow: https://www.tensorflow.org/
- TFLite: https://www.tensorflow.org/lite
- TensorBoard: https://www.tensorflow.org/tensorboard

---

## âœ… Checklist de ImplementaciÃ³n

### PreparaciÃ³n
- [ ] Descargar FER-2013
- [ ] (Opcional) Crear dataset custom
- [ ] Ejecutar `data_preparation.py`
- [ ] Verificar `data/processed/` creado

### Entrenamiento
- [ ] Seleccionar arquitectura (MobileNetV3 o Custom Light)
- [ ] Configurar hiperparÃ¡metros
- [ ] Ejecutar `train_model.py`
- [ ] Monitorear TensorBoard
- [ ] Verificar convergencia

### EvaluaciÃ³n
- [ ] Ejecutar `evaluate_model.py`
- [ ] Revisar classification report
- [ ] Analizar confusion matrix
- [ ] Identificar errores comunes
- [ ] Verificar KPI accuracy â‰¥ 84%

### OptimizaciÃ³n
- [ ] Convertir a TFLite INT8
- [ ] Ejecutar benchmark de latencia
- [ ] Verificar KPI latencia â‰¤ 200ms
- [ ] Probar en Raspberry Pi 5
- [ ] Ajustar si no cumple KPIs

### Despliegue
- [ ] Copiar `.tflite` a Raspberry Pi
- [ ] Integrar en sistema de monitoreo
- [ ] Pruebas end-to-end
- [ ] Monitoreo en producciÃ³n

---

**Gloria S.A. - Stress Vision**  
**Fase 4: Entrenamiento y OptimizaciÃ³n - Completada** âœ…


